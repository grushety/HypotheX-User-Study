{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“Œ Model Training & Data Analysis Script\n",
        "This Colab script:\n",
        "- Loads and preprocesses a dataset (human or animal dataset)\n",
        "- Trains multiple machine learning models\n",
        "- Evaluates models and selects the best one\n",
        "- Generates various performance metrics, visualizations, and feature importance scores\n",
        "- Provides downloadable trained models"
      ],
      "metadata": {
        "id": "fQLrrZN_aPaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries (if not already installed)\n",
        "!pip install pandas scikit-learn matplotlib seaborn joblib catboost --quiet\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import itertools\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
        "from sklearn.inspection import partial_dependence, PartialDependenceDisplay\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "# Define dataset type: \"humans\" or \"animals\"\n",
        "dataset_type = \"animals\""
      ],
      "metadata": {
        "id": "8WI1t39lhs9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hByFRalIeoXE"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# ðŸ“Œ Main Functions\n",
        "# ================================\n",
        "\n",
        "# Function to plot and save confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, labels, model_name, dataset_type, dataset_split):\n",
        "    \"\"\"Plot and save the confusion matrix as an image (.png) and return only the filename.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(f\"Confusion Matrix - {model_name} ({dataset_type}) [{dataset_split}]\")\n",
        "\n",
        "    # Save as PNG Image (only return filename)\n",
        "    img_filename = f\"{model_name}_{dataset_type}_confusion_matrix_{dataset_split}.png\"\n",
        "    plt.savefig(img_filename)\n",
        "    plt.close()  # Prevent extra display in notebooks\n",
        "\n",
        "    return img_filename\n",
        "\n",
        "\n",
        "def process_and_train_model(filename, use_cross_validation=True, cv_folds=5, model_choices=None):\n",
        "    \"\"\"\n",
        "    This function loads a dataset, processes it, applies cross-validation,\n",
        "    trains multiple models, evaluates them, and selects the best one.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(filename)\n",
        "    print(f\"Loaded\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Encode target variable\n",
        "    target_column = \"Class\"\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[target_column] = label_encoder.fit_transform(df[target_column])\n",
        "\n",
        "    # Prepare feature set and target\n",
        "    X = df.drop(columns=[target_column])\n",
        "    y = df[target_column]\n",
        "\n",
        "    # Split into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Define models\n",
        "    models = {\n",
        "        \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        \"XGBoost\": XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
        "        \"LightGBM\": LGBMClassifier(n_estimators=100, random_state=42, verbose=-1),\n",
        "        \"CatBoost\": CatBoostClassifier(iterations=100, verbose=0, random_state=42),\n",
        "        \"GradientBoosting\": GradientBoostingClassifier(n_estimators=100, random_state=42,verbose=0),\n",
        "        \"MLP\": MLPClassifier(hidden_layer_sizes=(100,50), max_iter=300, activation='relu', solver='adam', random_state=42, verbose=0),\n",
        "        \"ExtraTrees\": ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
        "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "        \"NaiveBayes\": GaussianNB(),\n",
        "        \"SVM\": SVC(kernel='rbf', probability=True, random_state=42)\n",
        "    }\n",
        "\n",
        "    # Allow selection of models to train\n",
        "    if model_choices is None:\n",
        "        model_choices = models.keys()  # Default: train all models\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Train and evaluate each selected model\n",
        "    for model_name in model_choices:\n",
        "        print(f\"\\nTraining {model_name}...\")\n",
        "        model = models[model_name]\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Predictions\n",
        "        y_train_pred = model.predict(X_train_scaled)\n",
        "        y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        # Compute accuracy\n",
        "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "        print(f\"{model_name} Train Accuracy: {train_accuracy:.4f} | Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "        # Compute confusion matrices for training and testing sets\n",
        "        # Compute confusion matrices & save images\n",
        "        train_cm_image = plot_confusion_matrix(y_train, y_train_pred, label_encoder.classes_, model_name, dataset_type, \"Train\")\n",
        "        test_cm_image = plot_confusion_matrix(y_test, y_test_pred, label_encoder.classes_, model_name, dataset_type, \"Test\")\n",
        "\n",
        "\n",
        "\n",
        "        # Find misclassified examples\n",
        "        misclassified = X_test.copy()\n",
        "        misclassified[\"Actual Class\"] = label_encoder.inverse_transform(y_test)\n",
        "        misclassified[\"Predicted Class\"] = label_encoder.inverse_transform(y_test_pred)\n",
        "        misclassified = misclassified[misclassified[\"Actual Class\"] != misclassified[\"Predicted Class\"]]\n",
        "\n",
        "        # Store results\n",
        "        results[model_name] = {\n",
        "            \"model\": model,\n",
        "            \"train_accuracy\": train_accuracy,\n",
        "            \"test_accuracy\": test_accuracy,\n",
        "            \"classification_report\": classification_report(y_test, y_test_pred, target_names=label_encoder.classes_, output_dict=True),\n",
        "            \"confusion_matrix_train\": train_cm_image,  # Train Confusion Matrix\n",
        "            \"confusion_matrix_test\": test_cm_image,    # Test Confusion Matrix\n",
        "            \"misclassified_samples\": misclassified  # Store misclassified examples\n",
        "        }\n",
        "\n",
        "    # Select best model based on test accuracy\n",
        "    best_model_name = max(results, key=lambda m: results[m]['test_accuracy'])\n",
        "    best_model = results[best_model_name][\"model\"]\n",
        "    print(f\"\\nBest model: {best_model_name} with Test Accuracy: {results[best_model_name]['test_accuracy']:.4f}\")\n",
        "\n",
        "    # Save the best model and preprocessing tools\n",
        "    joblib.dump(best_model, f\"{dataset_type}_{best_model_name}_classifier.pkl\")\n",
        "    joblib.dump(label_encoder, f\"{dataset_type}_label_encoder.pkl\")\n",
        "    joblib.dump(scaler, f\"{dataset_type}_scaler.pkl\")\n",
        "\n",
        "    print(f\"Best model ({best_model_name}) and preprocessing tools saved.\")\n",
        "\n",
        "    return df, X, y, X_test, y_test, label_encoder, best_model, results\n",
        "\n",
        "\n",
        "def save_all_models(results, dataset_type=\"dataset\"):\n",
        "    \"\"\"\n",
        "    Saves all trained models, scalers, label encoders, and evaluation metrics\n",
        "    into a structured directory for later retrieval.\n",
        "    \"\"\"\n",
        "    # Define the base directory\n",
        "    save_dir = f\"{dataset_type}_models\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Create a summary file\n",
        "    summary_filename = os.path.join(save_dir, \"model_summary.txt\")\n",
        "\n",
        "    with open(summary_filename, \"w\") as summary_file:\n",
        "        summary_file.write(f\"Model Training Summary for {dataset_type.capitalize()} Dataset\\n\")\n",
        "        summary_file.write(\"=\" * 50 + \"\\n\")\n",
        "\n",
        "        for model_name, model_data in results.items():\n",
        "            model_folder = os.path.join(save_dir, model_name)\n",
        "            os.makedirs(model_folder, exist_ok=True)\n",
        "\n",
        "            # Save the model\n",
        "            model_filename = os.path.join(model_folder, f\"{model_name}_classifier.pkl\")\n",
        "            joblib.dump(model_data[\"model\"], model_filename)\n",
        "\n",
        "            # Save the confusion matrices\n",
        "            cm_train_filename = os.path.join(model_folder, f\"{model_name}_confusion_matrix_train.npy\")\n",
        "            cm_test_filename = os.path.join(model_folder, f\"{model_name}_confusion_matrix_test.npy\")\n",
        "            np.save(cm_train_filename, model_data[\"confusion_matrix_train\"])\n",
        "            np.save(cm_test_filename, model_data[\"confusion_matrix_test\"])\n",
        "\n",
        "            # Save misclassified samples\n",
        "            misclassified_filename = os.path.join(model_folder, f\"{model_name}_misclassified_samples.csv\")\n",
        "            model_data[\"misclassified_samples\"].to_csv(misclassified_filename, index=False)\n",
        "\n",
        "            # Save classification report\n",
        "            classification_report_filename = os.path.join(model_folder, f\"{model_name}_classification_report.json\")\n",
        "            with open(classification_report_filename, \"w\") as report_file:\n",
        "                import json\n",
        "                json.dump(model_data[\"classification_report\"], report_file, indent=4)\n",
        "\n",
        "            # Write model summary\n",
        "            summary_file.write(f\"Model: {model_name}\\n\")\n",
        "            summary_file.write(f\"Train Accuracy: {model_data['train_accuracy']:.4f}\\n\")\n",
        "            summary_file.write(f\"Test Accuracy: {model_data['test_accuracy']:.4f}\\n\")\n",
        "            summary_file.write(f\"Confusion Matrices saved: Yes\\n\")\n",
        "            summary_file.write(f\"Misclassified Samples saved: {misclassified_filename}\\n\")\n",
        "            summary_file.write(f\"Classification Report saved: {classification_report_filename}\\n\")\n",
        "            summary_file.write(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "    print(f\" All models and details saved successfully in '{save_dir}' folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset file and train the models"
      ],
      "metadata": {
        "id": "81D3vqo9bDsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt user to upload CSV file\n",
        "print(\"Please upload the CSV file containing the dataset (Human or Animal).\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded filename\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Process the dataset and train model\n",
        "df, X, y, X_test, y_test, label_encoder, best_model, results = process_and_train_model(filename)\n",
        "\n",
        "save_all_models(results, dataset_type)"
      ],
      "metadata": {
        "id": "-AOFw5Hnm2dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show misclassified examples\n",
        "Other model options are : \"RandomForest\", \"XGBoost\", \"LightGBM\", \"CatBoost\", \"GradientBoosting\", \"MLP\", \"ExtraTrees\", \"KNN\", \"NaiveBayes\", \"SVM\"  "
      ],
      "metadata": {
        "id": "iA2Oz1fQbabo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_model = \"CatBoost\"  # CHANGE THIS TO THE MODEL FROM MODEL OPTIONS\n",
        "cm_train = results[selected_model][\"confusion_matrix_train\"]\n",
        "cm_test = results[selected_model][\"confusion_matrix_test\"]\n",
        "\n",
        "misclassified_samples = results[selected_model][\"misclassified_samples\"]\n",
        "\n",
        "for index, row in misclassified_samples.iterrows():\n",
        "    print(f\"Index: {index} | Actual: {row['Actual Class']} | Predicted: {row['Predicted Class']} | Features: {row.drop(['Actual Class', 'Predicted Class']).to_dict()}\")"
      ],
      "metadata": {
        "id": "i6sTl6WP0izv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Advanced Dataset Statistics\n",
        "# ===========================\n",
        "\n",
        "# Compute descriptive statistics including median, standard deviation, skewness, and kurtosis\n",
        "statistics_df = df.describe().T  # Transpose for better readability\n",
        "statistics_df[\"median\"] = df.median(numeric_only=True)\n",
        "statistics_df[\"std_dev\"] = df.std(numeric_only=True)\n",
        "statistics_df[\"skewness\"] = df.skew(numeric_only=True)\n",
        "statistics_df[\"kurtosis\"] = df.kurtosis(numeric_only=True)\n",
        "\n",
        "# Display dataset statistics\n",
        "print(\"\\n **Advanced Dataset Statistics:**\")\n",
        "print(statistics_df)\n",
        "\n",
        "# ===========================\n",
        "# Feature Correlation Matrix\n",
        "# ===========================\n",
        "\n",
        "# Compute correlation matrix\n",
        "correlation_matrix = df.corr(numeric_only=True)\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# ===========================\n",
        "# Feature Correlation Matrix per Class\n",
        "# ===========================\n",
        "\n",
        "# Get unique class labels\n",
        "unique_classes = df[\"Class\"].unique()\n",
        "print(unique_classes)\n",
        "\n",
        "# Create subplots for each class\n",
        "num_classes = len(unique_classes)\n",
        "fig, axes = plt.subplots(1, num_classes, figsize=(6 * num_classes, 5))\n",
        "\n",
        "# If there's only one class, axes will not be iterable, so convert to list\n",
        "if num_classes == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "# Generate correlation matrices for each class separately\n",
        "for i, class_label in enumerate(unique_classes):\n",
        "    class_df = df[df[\"Class\"] == class_label].drop(columns=[\"Class\"])  # Exclude target variable\n",
        "    print(len(class_df))\n",
        "\n",
        "    # Compute correlation matrix\n",
        "    correlation_matrix = class_df.corr(numeric_only=True)\n",
        "\n",
        "    # Plot the heatmap for each class\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5, ax=axes[i])\n",
        "    class_name = label_encoder.inverse_transform([class_label])[0]\n",
        "    axes[i].set_title(f\"Feature Correlation - {class_name}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# ===========================\n",
        "# Class Distribution Analysis\n",
        "# ===========================\n",
        "\n",
        "# Compute class distribution\n",
        "class_distribution = y.value_counts(normalize=True) * 100\n",
        "\n",
        "# Display class distribution statistics\n",
        "print(\"\\n **Class Distribution (% of total):**\")\n",
        "print(class_distribution)\n",
        "\n",
        "# Plot class distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x=y, palette=\"viridis\")\n",
        "plt.xticks(ticks=range(len(label_encoder.classes_)), labels=label_encoder.classes_)\n",
        "plt.title(f\"Class Distribution in Dataset\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# ===========================\n",
        "# Chi-Square Test for Feature Independence\n",
        "# ===========================\n",
        "\n",
        "chi2_results = {}\n",
        "for feature in X.columns:\n",
        "    contingency_table = pd.crosstab(df[feature], y)\n",
        "    chi2, p, _, _ = stats.chi2_contingency(contingency_table)\n",
        "    chi2_results[feature] = {\"Chi2\": chi2, \"p-value\": p}\n",
        "\n",
        "# Convert results to DataFrame for better readability\n",
        "chi2_df = pd.DataFrame(chi2_results).T\n",
        "\n",
        "# Display chi-square test results\n",
        "print(\"\\n **Chi-Square Test Results (Feature-Class Independence):**\")\n",
        "print(chi2_df)\n"
      ],
      "metadata": {
        "id": "n9cYSJRmm8_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importance scores\n",
        "model = results[\"RandomForest\"][\"model\"]\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "# Create a DataFrame for visualization\n",
        "feature_importance_df = pd.DataFrame({\"Feature\": X.columns, \"Importance\": feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=\"Importance\", y=\"Feature\", data=feature_importance_df, palette=\"viridis\")\n",
        "plt.title(f\"Feature Importance in {dataset_type.capitalize()} Classification\")\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FRV8RQyUnAF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit scaler on training data only\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)  # Fit only on training data\n",
        "\n",
        "# Transform train and test data while retaining feature names\n",
        "X_train_scaled = pd.DataFrame(scaler.transform(X), columns=X.columns)\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
        "\n",
        "# Convert scaled NumPy array back into DataFrame to retain feature names\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
        "# Select two interacting features for PDP\n",
        "if \"Gardening\" in X.columns and \"Detective Stories\" in X.columns:\n",
        "    interaction_features = [(\"Gardening\", \"Detective Stories\")]\n",
        "elif \"Online Hours\" in X.columns and \"Coffee\" in X.columns:\n",
        "    interaction_features = [(\"Online Hours\", \"Coffee\")]\n",
        "else:\n",
        "    interaction_features = []\n",
        "\n",
        "# Ensure that X_test_scaled retains feature names\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
        "\n",
        "# Get all class labels\n",
        "class_labels = label_encoder.classes_\n",
        "\n",
        "# Create PDP for each class\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "for i, target_class in enumerate(range(len(class_labels))):  # Iterate through all class indices (0, 1, 2)\n",
        "    PartialDependenceDisplay.from_estimator(\n",
        "        model, X_test_scaled, features=interaction_features, target=target_class, ax=axes[i]\n",
        "    )\n",
        "    axes[i].set_title(f\"2D Partial Dependence Plot for {class_labels[target_class]}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uoD0WU-0-uHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "# Generate all possible feature combinations\n",
        "feature_combinations = list(combinations(X.columns, 2))\n",
        "\n",
        "# Define number of feature combinations dynamically\n",
        "num_combinations = len(feature_combinations)\n",
        "\n",
        "# Define number of columns (3 per row) and calculate rows dynamically\n",
        "num_cols = 3  # Adjust the number of columns per row as needed\n",
        "num_rows = int(np.ceil(num_combinations / num_cols))  # Calculate required rows\n",
        "\n",
        "# Define class colors for visualization\n",
        "unique_classes = np.unique(y)  # Get unique class labels\n",
        "colors = [\"red\", \"blue\", \"green\", \"purple\", \"orange\", \"brown\"]  # Define a color palette\n",
        "class_colors = {class_label: colors[i % len(colors)] for i, class_label in enumerate(unique_classes)}\n",
        "\n",
        "# Add small random noise (jitter) to avoid exact overlapping points\n",
        "jitter_strength = 0.3  # Adjust as needed\n",
        "\n",
        "# Create figure dynamically based on the number of rows and columns\n",
        "plt.figure(figsize=(num_cols * 5, num_rows * 5))  # Adjust figure size dynamically\n",
        "\n",
        "# Loop through all feature combinations and plot them dynamically\n",
        "for i, (feat1, feat2) in enumerate(feature_combinations):\n",
        "    plt.subplot(num_rows, num_cols, i + 1)\n",
        "\n",
        "    # Plot each class with jitter added\n",
        "    for class_label in np.unique(y):\n",
        "        mask = y == class_label\n",
        "        x_jittered = X.loc[mask, feat1] + np.random.uniform(-jitter_strength, jitter_strength, size=sum(mask))\n",
        "        y_jittered = X.loc[mask, feat2] + np.random.uniform(-jitter_strength, jitter_strength, size=sum(mask))\n",
        "\n",
        "        plt.scatter(\n",
        "            x_jittered, y_jittered,\n",
        "            color=class_colors[class_label],\n",
        "            label=label_encoder.inverse_transform([class_label])[0],\n",
        "            alpha=0.5,\n",
        "            edgecolors=\"k\"\n",
        "        )\n",
        "\n",
        "    plt.xlabel(feat1)\n",
        "    plt.ylabel(feat2)\n",
        "    plt.title(f\"{feat1} vs {feat2} Classification\")\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()  # Optimize subplot spacing\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "4HDPZ81anC07"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}